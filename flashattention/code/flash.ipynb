{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U3nQMf-ky-vc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch==2.7.1 in /root/miniforge3/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision==0.22.1 in /root/miniforge3/lib/python3.10/site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio==2.7.1 in /root/miniforge3/lib/python3.10/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /root/miniforge3/lib/python3.10/site-packages (from torch==2.7.1) (3.3.1)\n",
      "Requirement already satisfied: numpy in /root/miniforge3/lib/python3.10/site-packages (from torchvision==0.22.1) (1.23.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniforge3/lib/python3.10/site-packages (from torchvision==0.22.1) (11.0.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniforge3/lib/python3.10/site-packages (from triton==3.3.1->torch==2.7.1) (75.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniforge3/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.7.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniforge3/lib/python3.10/site-packages (from jinja2->torch==2.7.1) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: http://mirrors.tencentyun.com/pypi/simple\n",
      "Requirement already satisfied: numpy==1.23.3 in /root/miniforge3/lib/python3.10/site-packages (1.23.3)\n",
      "Requirement already satisfied: pandas in /root/miniforge3/lib/python3.10/site-packages (2.3.2)\n",
      "Requirement already satisfied: triton in /root/miniforge3/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: matplotlib in /root/miniforge3/lib/python3.10/site-packages (3.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniforge3/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniforge3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /root/miniforge3/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /root/miniforge3/lib/python3.10/site-packages (from triton) (75.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /root/miniforge3/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /root/miniforge3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install numpy==1.23.3 pandas triton matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "# 为啥不把所有参数都声明为constexpr？？\n",
    "def flash_attention_v1(\n",
    "    q_ptr, k_ptr, v_ptr, o_ptr,\n",
    "    seq_len, d_model: tl.constexpr,\n",
    "    stride_qm, stride_km, stride_vm,\n",
    "    BLOCK_M: tl.constexpr,\n",
    "    BLOCK_N: tl.constexpr,\n",
    "    BLOCK_D: tl.constexpr,\n",
    "):\n",
    "    # 每个program处理一个BLOCK_M*BLOCK_D的子矩阵\n",
    "    # program和thread有啥区别？？\n",
    "    pid_m = tl.program_id(0)\n",
    "    pid_d = tl.program_id(1)\n",
    "    \n",
    "    start_m = pid_m * BLOCK_M\n",
    "    start_d = pid_d * BLOCK_D\n",
    "    \n",
    "    offs_m = start_m + tl.arange(0, BLOCK_M)\n",
    "    offs_d = start_d + tl.arange(0, BLOCK_D)\n",
    "    \n",
    "    # 初始化m l o\n",
    "    m_prev = tl.full((BLOCK_M,), float('-inf'), dtype=tl.float32)\n",
    "    l_prev = tl.zeros((BLOCK_M,), dtype=tl.float32)\n",
    "    acc = tl.zeros((BLOCK_M, BLOCK_D), dtype=tl.float32)\n",
    "    \n",
    "    # 加载Q分块，并利用mask确保不越界访问，对越界位置填0\n",
    "    q = tl.load(\n",
    "        q_ptr + offs_m[:, None] * stride_qm + offs_d[None, :],\n",
    "        mask=(offs_m[:, None] < seq_len) & (offs_d[None, :] < d_model),\n",
    "        other=0.0\n",
    "    )\n",
    "    \n",
    "    # 这里采用了flash attention 2中的block内的分工\n",
    "    # 即通过将flash attention 1的内外循环颠倒，来减少warp间的通信代价\n",
    "    # 现在每个warp都会计算一个完整的Q小块，而非每个Q小块的一部分\n",
    "    for start_n in range(0, seq_len, BLOCK_N):\n",
    "        offs_n = start_n + tl.arange(0, BLOCK_N)\n",
    "        mask_n = offs_n < seq_len\n",
    "        \n",
    "        # 加载K分块\n",
    "        k = tl.load(\n",
    "            k_ptr + offs_n[:, None] * stride_km + offs_d[None, :],\n",
    "            mask=mask_n[:, None] & (offs_d[None, :] < d_model),\n",
    "            other=0.0\n",
    "        )\n",
    "        \n",
    "        # 加载V分块\n",
    "        v = tl.load(\n",
    "            v_ptr + offs_n[:, None] * stride_vm + offs_d[None, :],\n",
    "            mask=mask_n[:, None] & (offs_d[None, :] < d_model),\n",
    "            other=0.0\n",
    "        )\n",
    "        \n",
    "        # 计算QK^T\n",
    "        s = tl.dot(q, k.T)\n",
    "        s *= 1.0 / tl.sqrt(tl.cast(d_model, s.dtype))\n",
    "        \n",
    "        # 掩码无效位置\n",
    "        s = tl.where(mask_n[None, :], s, float('-inf'))\n",
    "        \n",
    "        # 修正的在线Softmax\n",
    "        m_current = tl.maximum(tl.max(s, axis=1), m_prev)\n",
    "        \n",
    "        # 数值稳定的指数计算\n",
    "        exp_m_prev = tl.exp(m_prev - m_current)\n",
    "        exp_s = tl.exp(s - m_current[:, None])\n",
    "        \n",
    "        l_current = exp_m_prev * l_prev + tl.sum(exp_s, axis=1)\n",
    "        \n",
    "        # 更新累加器\n",
    "        acc = acc * exp_m_prev[:, None] + tl.dot(exp_s, v)\n",
    "        \n",
    "        # 更新状态\n",
    "        m_prev = m_current\n",
    "        l_prev = l_current\n",
    "    \n",
    "    # 归一化并写入结果\n",
    "    acc = acc / l_prev[:, None]\n",
    "    tl.store(\n",
    "        o_ptr + offs_m[:, None] * stride_qm + offs_d[None, :],\n",
    "        acc,\n",
    "        mask=(offs_m[:, None] < seq_len) & (offs_d[None, :] < d_model)\n",
    "    )\n",
    "\n",
    "def call_flash_attention_v1(q, k, v):\n",
    "    assert q.shape == k.shape == v.shape\n",
    "    seq_len, d_model = q.shape\n",
    "    \n",
    "    # 怎么分块？？为啥有三个BLOCK_X\n",
    "    BLOCK_M = 64\n",
    "    BLOCK_N = 64\n",
    "    BLOCK_D = 64\n",
    "    \n",
    "    o = torch.empty_like(q)\n",
    "    \n",
    "    grid = (\n",
    "        triton.cdiv(seq_len, BLOCK_M),\n",
    "        triton.cdiv(d_model, BLOCK_D)\n",
    "    )\n",
    "    \n",
    "    flash_attention_v1[grid](\n",
    "        q, k, v, o,\n",
    "        seq_len, d_model,\n",
    "        q.stride(0), k.stride(0), v.stride(0),\n",
    "        BLOCK_M=BLOCK_M,\n",
    "        BLOCK_N=BLOCK_N,\n",
    "        BLOCK_D=BLOCK_D,\n",
    "    )\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大绝对误差: 2.682209014892578e-07\n",
      "是否近似相等: True\n"
     ]
    }
   ],
   "source": [
    "def torch_attention(q, k, v):\n",
    "    # d_k = d_model\n",
    "    d_k = q.size(-1)\n",
    "    # 为了防止注意力分数方差过大导致softmax梯度消失，需要根号下d_k这个缩放因子\n",
    "    # 方差​​就是​​衡量一组数据与其平均值的偏离程度​\n",
    "    # softmax函数对极端输入值非常敏感\n",
    "    attn_scores = q @ k.transpose(-2, -1) / (d_k ** 0.5) \n",
    "    # 在最后一个维度上进行softmax操作\n",
    "    attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "    return attn_probs @ v \n",
    "\n",
    "# 序列长度\n",
    "seq_len = 128  \n",
    "# 特征维度\n",
    "d_model = 64 \n",
    "\n",
    "# 初始化Q K V输入\n",
    "q = torch.randn(seq_len, d_model, device=\"cuda\", dtype=torch.float32)\n",
    "k = torch.randn_like(q)\n",
    "v = torch.randn_like(q)\n",
    "\n",
    "# 用 Triton 计算\n",
    "o_triton = call_flash_attention_v1(q, k, v)\n",
    "# 用 PyTorch 计算\n",
    "o_torch = torch_attention(q, k, v)\n",
    "\n",
    "print(\"最大绝对误差:\", (o_triton - o_torch).abs().max().item())\n",
    "# 对于两个张量中的每个对应元素都应该满足\n",
    "# |o_triton - o_torch| ≤ atol + rtol × |o_torch|\n",
    "print(\"是否近似相等:\", torch.allclose(o_triton, o_torch, atol=1e-2, rtol=1e-2))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
